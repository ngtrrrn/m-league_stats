# -*- coding: utf-8 -*-
"""scraping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V0Q4tX6Z9hpany3dyhrjbftOBxxce3Ae

# 前提準備
"""

from bs4 import BeautifulSoup
import requests

# 対象となるサイトのhtmlを与える
html_doc_list = {}

html_doc = requests.get("https://m-league.jp/stats/").text
# BeautifulSoupの初期化
soup = BeautifulSoup(html_doc, 'html.parser')

"""# データのスクレイピング"""

## データのスクレイピング
column = []
#項目の読み込み
tmp = ['チーム名']
for th in soup.find_all("section")[0].find_all(scope="row"):
  tmp.append(th.text)
column.append(tmp)
print(column)


data=[]
for section in soup.find_all("section"):

  # チーム名
  teamName = section.select("h2")[0].text.strip()

  #成績テーブル読みこみ
  statsTable = section.find("table")
  statsRow = statsTable.find_all("tr")[0]

  # （選手の人数＋項目行数）
  num = len(statsRow.find_all("th"))

  # 選手データの読み込み
  for i in range(num):
    if i > 0:  
      tmp=[teamName]
      for  j, tr in enumerate(statsTable.find_all("tr")):
        if j > 0:
          td = tr.find_all("td")[i-1]
          tmp.append(td.text)
        else:
          th = tr.find_all("th")[i]
          tmp.append(th.text)
      data.append(tmp)

print(data)

"""# DataFrameに変換"""

import pandas as pd

df = pd.DataFrame(data, columns=column)
df.to_csv('data.csv')

print(df)